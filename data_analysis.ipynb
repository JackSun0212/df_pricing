{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "import os\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "from utils import *\n",
    "from preprocessing import *\n",
    "from models import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_descr(x):\n",
    "    '''\n",
    "    valid output :\n",
    "    Airframe, Avionics, Paint, Engine, APU, Interior Modification, \n",
    "    Engineering, Rework, Other Miscellaneous Charge, Structural Repair\n",
    "    \n",
    "    other values found (converted to NaN):\n",
    "        '307',   'tfe731',\n",
    "        'aircraft',      'aircraft maintenance',\n",
    "        'amendment of stc st02976ny non lpv equip',\n",
    "        'caac validation for avixaero landing gear stc',\n",
    "        'collins dual ahrs cl600-2b16',\n",
    "        'conformity and flight test for wo 40250 casa cn235 project oda2ny-0064',\n",
    "        'customer assist',\n",
    "        'falcon 2000', 'falcon 2000lxs',  'falcon 7x',\n",
    "        'falcon 900', 'falcon 900dx',   'falcon 900ex',\n",
    "        'gmm rii items',  'rii requirements',\n",
    "        'modification', 'modifications',\n",
    "        'netjet credits',  'netjets rii section',\n",
    "        'oda', 'southwest psu (amendment)',\n",
    "        'stc certification of gogo satcom',\n",
    "        'stc laseref iv aml stc',\n",
    "        'weight and balance computation']\n",
    "    '''\n",
    "    if type(x)!=str:\n",
    "        x=str(x)\n",
    "    x=x.lower().strip()\n",
    "    \n",
    "    if x in ['engine','engine #1','engine #2','engine #3','#2 engine','engine # 1', 'enigine #1', 'engnie #1']:\n",
    "        return 'Engine'\n",
    "        \n",
    "    elif x in ['airframe','airrfame','ariframe', 'airfame']: \n",
    "        return 'Airframe'\n",
    "        \n",
    "    elif x=='paint':\n",
    "        return 'Paint'\n",
    "    \n",
    "    elif x=='apu':\n",
    "        return 'APU'\n",
    "        \n",
    "    elif x in ['avionics','avioinics']:\n",
    "        return 'Avionics'\n",
    "    \n",
    "    elif x in ['interior modifications','interior modifcations','interior modification',\n",
    "               'interior moficiations','interior modfications','interiors modifications','inteiror modifications']:\n",
    "        return 'Interior Modification'\n",
    "        \n",
    "    elif x in ['engineering','engneering','engineeering','engineering items','miggitt isfd updates engineering po sc-03235',\n",
    "               'oda engineering', 'engineering oda', 'engineering sc17-02520','engineering support for csq15-00058']:\n",
    "        return 'Engineering'\n",
    "        \n",
    "    elif x in ['rework','rework item','rework-','.rework', 're-work']:\n",
    "        return 'Rework'\n",
    "        \n",
    "    elif x in ['structural repair','structural repairs']:\n",
    "        return 'Structural Repair'\n",
    "        \n",
    "    elif x in ['other miscellaneous charges','other miscellaneeous charges','othe miscellaneous charges',\n",
    "               'other miscellanesous charges','miscellaneous charges','other miscellanious charges',\n",
    "               'miscelaneous charges','other misc charges','other miscellaneous', 'other miscellaneous items']:\n",
    "        return 'Other Miscellaneous Charge'\n",
    "    \n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wil = pd.read_csv(get_data_path('wilmington'))\n",
    "columns_of_interest = ['WORKORDERKEY', 'DESCRIPTION',\n",
    "                       #labor\n",
    "                       'TOTALLABORESTIMATEDCOST', 'TOTALLABORCOST', \n",
    "                       'TOTALLABORESTIMATEDREVENUE', 'TOTALLABORREVENUE',\n",
    "                       #parts\n",
    "                       'TOTALPARTSESTIMATEDCOST', 'TOTALPARTSCOST',\n",
    "                       'TOTALPARTSESTIMATEDREVENUE', 'TOTALPARTSREVENUE',\n",
    "                       #labor hours\n",
    "                       'ESTIMATEDLABORCOSTHOURS', 'ACTUALLABORCOSTHOURS',\n",
    "                       #'ESTIMATEDLABORREVENUEHOURS', 'ACTUALLABORREVENUEHOURS'\n",
    "                       \n",
    "                       ]\n",
    "\n",
    "df_i = wil[columns_of_interest]\n",
    "df_i['description']=df_i.DESCRIPTION.apply(clean_descr)\n",
    "df_i.drop('DESCRIPTION', axis=1, inplace=True)\n",
    "df_group = df_i.groupby(['WORKORDERKEY', 'description']).sum().reset_index(level=(1))\n",
    "\n",
    "df_group['LABOR_MARGIN']=df_group.TOTALLABORREVENUE - df_group.TOTALLABORCOST\n",
    "df_group['PARTS_MARGIN']=df_group.TOTALPARTSREVENUE - df_group.TOTALPARTSCOST\n",
    "\n",
    "df_group['EST_LABOR_MARGIN']=df_group.TOTALLABORESTIMATEDREVENUE - df_group.TOTALLABORESTIMATEDCOST\n",
    "df_group['EST_PARTS_MARGIN']=df_group.TOTALPARTSESTIMATEDREVENUE - df_group.TOTALPARTSESTIMATEDCOST\n",
    "\n",
    "df_group['cost_error']=df_group.ESTIMATEDLABORCOSTHOURS - df_group.ACTUALLABORCOSTHOURS\n",
    "\n",
    "\n",
    "total_count = df_group.groupby('description').LABOR_MARGIN.count().rename('Total number of WO')\n",
    "\n",
    "neg_labor = df_group[df_group.LABOR_MARGIN<0].groupby('description').LABOR_MARGIN.count()\n",
    "neg_parts = df_group[df_group.PARTS_MARGIN<0].groupby('description').PARTS_MARGIN.count()\n",
    "neg_cost_err = df_group[df_group.cost_error<0].groupby('description').cost_error.count()\n",
    "\n",
    "less_labor = df_group[df_group.EST_LABOR_MARGIN>df_group.LABOR_MARGIN].groupby('description').LABOR_MARGIN.count()\n",
    "less_parts = df_group[df_group.EST_PARTS_MARGIN>df_group.PARTS_MARGIN].groupby('description').PARTS_MARGIN.count()\n",
    "\n",
    "neg_labor_p = 100*(neg_labor/total_count).rename('Negative Labor Margin').round(3)\n",
    "neg_parts_p = 100*(neg_parts/total_count).rename('Negative Parts Margin').round(3)\n",
    "neg_cost_err_p = 100*(neg_cost_err/total_count).rename('Underestimated Cost Hours').round(3)\n",
    "\n",
    "less_labor_p = 100*(less_labor/total_count).rename('Labor Margin less than expected').round(3)\n",
    "less_parts_p = 100*(less_parts/total_count).rename('Parts Margin less than expected').round(3)\n",
    "\n",
    "res_w = pd.concat([total_count, neg_labor_p, neg_parts_p, neg_cost_err_p,  less_labor_p,less_parts_p], axis=1).drop('').reset_index().fillna(0)\n",
    "\n",
    "res_w.to_csv('wilmington_data_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reno = pd.read_csv(get_data_path('reno'))\n",
    "columns_of_interest = ['WORKORDERKEY', 'DESCRIPTION',\n",
    "                       #labor\n",
    "                       'TOTALLABORESTIMATEDCOST', 'TOTALLABORCOST', \n",
    "                       'TOTALLABORESTIMATEDREVENUE', 'TOTALLABORREVENUE',\n",
    "                       #parts\n",
    "                       'TOTALPARTSESTIMATEDCOST', 'TOTALPARTSCOST',\n",
    "                       'TOTALPARTSESTIMATEDREVENUE', 'TOTALPARTSREVENUE',\n",
    "                       #labor hours\n",
    "                       'ESTIMATEDLABORCOSTHOURS', 'ACTUALLABORCOSTHOURS',\n",
    "                       'ESTIMATEDLABORREVENUEHOURS', 'ACTUALLABORREVENUEHOURS'\n",
    "                       \n",
    "                       ]\n",
    "\n",
    "df_i = reno[columns_of_interest]\n",
    "df_i['description']=df_i.DESCRIPTION.apply(clean_descr)\n",
    "df_i.drop('DESCRIPTION', axis=1, inplace=True)\n",
    "df_group = df_i.groupby(['WORKORDERKEY', 'description']).sum().reset_index(level=(1))\n",
    "\n",
    "df_group['LABOR_MARGIN']=df_group.TOTALLABORREVENUE - df_group.TOTALLABORCOST\n",
    "df_group['PARTS_MARGIN']=df_group.TOTALPARTSREVENUE - df_group.TOTALPARTSCOST\n",
    "\n",
    "df_group['EST_LABOR_MARGIN']=df_group.TOTALLABORESTIMATEDREVENUE - df_group.TOTALLABORESTIMATEDCOST\n",
    "df_group['EST_PARTS_MARGIN']=df_group.TOTALPARTSESTIMATEDREVENUE - df_group.TOTALPARTSESTIMATEDCOST\n",
    "\n",
    "df_group['cost_error']=df_group.ESTIMATEDLABORCOSTHOURS - df_group.ACTUALLABORCOSTHOURS\n",
    "\n",
    "\n",
    "total_count = df_group.groupby('description').LABOR_MARGIN.count().rename('Total number of WO')\n",
    "\n",
    "neg_labor = df_group[df_group.LABOR_MARGIN<0].groupby('description').LABOR_MARGIN.count()\n",
    "neg_parts = df_group[df_group.PARTS_MARGIN<0].groupby('description').PARTS_MARGIN.count()\n",
    "neg_cost_err = df_group[df_group.cost_error<0].groupby('description').cost_error.count()\n",
    "\n",
    "less_labor = df_group[df_group.EST_LABOR_MARGIN>df_group.LABOR_MARGIN].groupby('description').LABOR_MARGIN.count()\n",
    "less_parts = df_group[df_group.EST_PARTS_MARGIN>df_group.PARTS_MARGIN].groupby('description').PARTS_MARGIN.count()\n",
    "\n",
    "neg_labor_p = 100*(neg_labor/total_count).rename('Negative Labor Margin').round(3)\n",
    "neg_parts_p = 100*(neg_parts/total_count).rename('Negative Parts Margin').round(3)\n",
    "neg_cost_err_p = 100*(neg_cost_err/total_count).rename('Underestimated Cost Hours').round(3)\n",
    "\n",
    "less_labor_p = 100*(less_labor/total_count).rename('Labor Margin less than expected').round(3)\n",
    "less_parts_p = 100*(less_parts/total_count).rename('Parts Margin less than expected').round(3)\n",
    "\n",
    "res_w = pd.concat([total_count, neg_labor_p, neg_parts_p, neg_cost_err_p,  less_labor_p,less_parts_p], axis=1).drop('').reset_index().fillna(0)\n",
    "\n",
    "\n",
    "res_w.to_csv('reno_data_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = pd.read_csv(get_data_path('littlerock'))\n",
    "columns_of_interest = ['WORKORDERKEY', 'DESCRIPTION',\n",
    "                       #labor\n",
    "                       'TOTALLABORESTIMATEDCOST', 'TOTALLABORCOST', \n",
    "                       'TOTALLABORESTIMATEDREVENUE', 'TOTALLABORREVENUE',\n",
    "                       #parts\n",
    "                       'TOTALPARTSESTIMATEDCOST', 'TOTALPARTSCOST',\n",
    "                       'TOTALPARTSESTIMATEDREVENUE', 'TOTALPARTSREVENUE',\n",
    "                       #labor hours\n",
    "                       'ESTIMATEDLABORCOSTHOURS', 'ACTUALLABORCOSTHOURS',\n",
    "                       'ESTIMATEDLABORREVENUEHOURS', 'ACTUALLABORREVENUEHOURS'\n",
    "                       \n",
    "                       ]\n",
    "\n",
    "df_i = lr[columns_of_interest]\n",
    "df_i['description']=df_i.DESCRIPTION.apply(clean_descr)\n",
    "df_i.drop('DESCRIPTION', axis=1, inplace=True)\n",
    "df_group = df_i.groupby(['WORKORDERKEY', 'description']).sum().reset_index(level=(1))\n",
    "\n",
    "df_group['LABOR_MARGIN']=df_group.TOTALLABORREVENUE - df_group.TOTALLABORCOST\n",
    "df_group['PARTS_MARGIN']=df_group.TOTALPARTSREVENUE - df_group.TOTALPARTSCOST\n",
    "\n",
    "df_group['EST_LABOR_MARGIN']=df_group.TOTALLABORESTIMATEDREVENUE - df_group.TOTALLABORESTIMATEDCOST\n",
    "df_group['EST_PARTS_MARGIN']=df_group.TOTALPARTSESTIMATEDREVENUE - df_group.TOTALPARTSESTIMATEDCOST\n",
    "\n",
    "df_group['cost_error']=df_group.ESTIMATEDLABORCOSTHOURS - df_group.ACTUALLABORCOSTHOURS\n",
    "\n",
    "\n",
    "total_count = df_group.groupby('description').LABOR_MARGIN.count().rename('Total number of WO')\n",
    "\n",
    "neg_labor = df_group[df_group.LABOR_MARGIN<0].groupby('description').LABOR_MARGIN.count()\n",
    "neg_parts = df_group[df_group.PARTS_MARGIN<0].groupby('description').PARTS_MARGIN.count()\n",
    "neg_cost_err = df_group[df_group.cost_error<0].groupby('description').cost_error.count()\n",
    "\n",
    "less_labor = df_group[df_group.EST_LABOR_MARGIN>df_group.LABOR_MARGIN].groupby('description').LABOR_MARGIN.count()\n",
    "less_parts = df_group[df_group.EST_PARTS_MARGIN>df_group.PARTS_MARGIN].groupby('description').PARTS_MARGIN.count()\n",
    "\n",
    "neg_labor_p = 100*(neg_labor/total_count).rename('Negative Labor Margin').round(3)\n",
    "neg_parts_p = 100*(neg_parts/total_count).rename('Negative Parts Margin').round(3)\n",
    "neg_cost_err_p = 100*(neg_cost_err/total_count).rename('Underestimated Cost Hours').round(3)\n",
    "\n",
    "less_labor_p = 100*(less_labor/total_count).rename('Labor Margin less than expected').round(3)\n",
    "less_parts_p = 100*(less_parts/total_count).rename('Parts Margin less than expected').round(3)\n",
    "\n",
    "res_w = pd.concat([total_count, neg_labor_p, neg_parts_p, neg_cost_err_p,  less_labor_p,less_parts_p], axis=1).drop('').reset_index().fillna(0)\n",
    "\n",
    "\n",
    "res_w.to_csv('littlerock_data_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wil = pd.read_csv(get_data_path('wilmington'))\n",
    "columns_of_interest = ['WORKORDERKEY', 'ITEMNUMBER',\n",
    "                       'TOTALLABORESTIMATEDCOST', 'TOTALLABORESTIMATEDREVENUE',\n",
    "                       'TOTALPARTSESTIMATEDCOST', 'TOTALPARTSESTIMATEDREVENUE',\n",
    "                       'TOTALPARTSCOST','TOTALPARTSREVENUE','TOTALLABORREVENUE','TOTALLABORCOST'\n",
    "                       ]\n",
    "df_i = wil[columns_of_interest]\n",
    "df_group = df_i.groupby(['WORKORDERKEY', 'ITEMNUMBER']).sum().reset_index(level=(1))\n",
    "df_group['LABOR_MARGIN']=df_group.TOTALLABORREVENUE - df_group.TOTALLABORCOST\n",
    "df_group['PARTS_MARGIN']=df_group.TOTALPARTSREVENUE - df_group.TOTALPARTSCOST\n",
    "\n",
    "df_group['EST_LABOR_MARGIN']=df_group.TOTALLABORESTIMATEDREVENUE - df_group.TOTALLABORESTIMATEDCOST\n",
    "df_group['EST_PARTS_MARGIN']=df_group.TOTALPARTSESTIMATEDREVENUE - df_group.TOTALPARTSESTIMATEDCOST\n",
    "\n",
    "total_count = df_group.groupby('ITEMNUMBER').LABOR_MARGIN.count().rename('Total number of WO')\n",
    "neg_labor = df_group[df_group.LABOR_MARGIN<0].groupby('ITEMNUMBER').LABOR_MARGIN.count()\n",
    "neg_parts = df_group[df_group.PARTS_MARGIN<0].groupby('ITEMNUMBER').PARTS_MARGIN.count()\n",
    "\n",
    "less_labor = df_group[df_group.EST_LABOR_MARGIN>df_group.LABOR_MARGIN].groupby('ITEMNUMBER').LABOR_MARGIN.count()\n",
    "less_parts = df_group[df_group.EST_PARTS_MARGIN>df_group.PARTS_MARGIN].groupby('ITEMNUMBER').PARTS_MARGIN.count()\n",
    "\n",
    "neg_labor_p = 100*(neg_labor/total_count).rename('Negative Labor Margin').round(3)\n",
    "neg_parts_p = 100*(neg_parts/total_count).rename('Negative Parts Margin').round(3)\n",
    "\n",
    "less_labor_p = 100*(less_labor/total_count).rename('Labor Margin less than expected').round(3)\n",
    "less_parts_p = 100*(less_parts/total_count).rename('Parts Margin less than expected').round(3)\n",
    "\n",
    "res_w = pd.concat([neg_labor_p, neg_parts_p,less_labor_p,less_parts_p], axis=1).reset_index()\n",
    "res_w.to_csv('wilmington_data_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reno = pd.read_csv(get_data_path('reno'))\n",
    "columns_of_interest = ['WORKORDERKEY', 'ITEMNUMBER',\n",
    "                       'TOTALLABORESTIMATEDCOST', 'TOTALLABORESTIMATEDREVENUE',\n",
    "                       'TOTALPARTSESTIMATEDCOST', 'TOTALPARTSESTIMATEDREVENUE',\n",
    "                       'TOTALPARTSCOST','TOTALPARTSREVENUE','TOTALLABORREVENUE','TOTALLABORCOST'\n",
    "                       ]\n",
    "df_i = reno[columns_of_interest]\n",
    "df_group = df_i.groupby(['WORKORDERKEY', 'ITEMNUMBER']).sum().reset_index(level=(1))\n",
    "df_group['LABOR_MARGIN']=df_group.TOTALLABORREVENUE - df_group.TOTALLABORCOST\n",
    "df_group['PARTS_MARGIN']=df_group.TOTALPARTSREVENUE - df_group.TOTALPARTSCOST\n",
    "\n",
    "df_group['EST_LABOR_MARGIN']=df_group.TOTALLABORESTIMATEDREVENUE - df_group.TOTALLABORESTIMATEDCOST\n",
    "df_group['EST_PARTS_MARGIN']=df_group.TOTALPARTSESTIMATEDREVENUE - df_group.TOTALPARTSESTIMATEDCOST\n",
    "\n",
    "total_count = df_group.groupby('ITEMNUMBER').LABOR_MARGIN.count().rename('Total number of WO')\n",
    "neg_labor = df_group[df_group.LABOR_MARGIN<0].groupby('ITEMNUMBER').LABOR_MARGIN.count()\n",
    "neg_parts = df_group[df_group.PARTS_MARGIN<0].groupby('ITEMNUMBER').PARTS_MARGIN.count()\n",
    "\n",
    "less_labor = df_group[df_group.EST_LABOR_MARGIN>df_group.LABOR_MARGIN].groupby('ITEMNUMBER').LABOR_MARGIN.count()\n",
    "less_parts = df_group[df_group.EST_PARTS_MARGIN>df_group.PARTS_MARGIN].groupby('ITEMNUMBER').PARTS_MARGIN.count()\n",
    "\n",
    "neg_labor_p = 100*(neg_labor/total_count).rename('Negative Labor Margin').round(3)\n",
    "neg_parts_p = 100*(neg_parts/total_count).rename('Negative Parts Margin').round(3)\n",
    "\n",
    "less_labor_p = 100*(less_labor/total_count).rename('Labor Margin less than expected').round(3)\n",
    "less_parts_p = 100*(less_parts/total_count).rename('Parts Margin less than expected').round(3)\n",
    "\n",
    "res_r = pd.concat([neg_labor_p, neg_parts_p,less_labor_p,less_parts_p], axis=1).reset_index()\n",
    "res_r.to_csv('reno_data_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lirock = pd.read_csv(get_data_path('littlerock'))\n",
    "columns_of_interest = ['WORKORDERKEY', 'ITEMNUMBER',\n",
    "                       'TOTALLABORESTIMATEDCOST', 'TOTALLABORESTIMATEDREVENUE',\n",
    "                       'TOTALPARTSESTIMATEDCOST', 'TOTALPARTSESTIMATEDREVENUE',\n",
    "                       'TOTALPARTSCOST','TOTALPARTSREVENUE','TOTALLABORREVENUE','TOTALLABORCOST'\n",
    "                       ]\n",
    "df_i = lirock[columns_of_interest]\n",
    "df_group = df_i.groupby(['WORKORDERKEY', 'ITEMNUMBER']).sum().reset_index(level=(1))\n",
    "df_group['LABOR_MARGIN']=df_group.TOTALLABORREVENUE - df_group.TOTALLABORCOST\n",
    "df_group['PARTS_MARGIN']=df_group.TOTALPARTSREVENUE - df_group.TOTALPARTSCOST\n",
    "\n",
    "df_group['EST_LABOR_MARGIN']=df_group.TOTALLABORESTIMATEDREVENUE - df_group.TOTALLABORESTIMATEDCOST\n",
    "df_group['EST_PARTS_MARGIN']=df_group.TOTALPARTSESTIMATEDREVENUE - df_group.TOTALPARTSESTIMATEDCOST\n",
    "\n",
    "total_count = df_group.groupby('ITEMNUMBER').LABOR_MARGIN.count().rename('Total number of WO')\n",
    "neg_labor = df_group[df_group.LABOR_MARGIN<0].groupby('ITEMNUMBER').LABOR_MARGIN.count()\n",
    "neg_parts = df_group[df_group.PARTS_MARGIN<0].groupby('ITEMNUMBER').PARTS_MARGIN.count()\n",
    "\n",
    "less_labor = df_group[df_group.EST_LABOR_MARGIN>df_group.LABOR_MARGIN].groupby('ITEMNUMBER').LABOR_MARGIN.count()\n",
    "less_parts = df_group[df_group.EST_PARTS_MARGIN>df_group.PARTS_MARGIN].groupby('ITEMNUMBER').PARTS_MARGIN.count()\n",
    "\n",
    "neg_labor_p = 100*(neg_labor/total_count).rename('Negative Labor Margin').round(3)\n",
    "neg_parts_p = 100*(neg_parts/total_count).rename('Negative Parts Margin').round(3)\n",
    "\n",
    "less_labor_p = 100*(less_labor/total_count).rename('Labor Margin less than expected').round(3)\n",
    "less_parts_p = 100*(less_parts/total_count).rename('Parts Margin less than expected').round(3)\n",
    "\n",
    "res_l = pd.concat([neg_labor_p, neg_parts_p,less_labor_p,less_parts_p], axis=1).reset_index()\n",
    "res_l.to_csv('littlerock_data_analysis.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
